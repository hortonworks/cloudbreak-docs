<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        
        
        <link rel="canonical" href="http://sequenceiq.com/cloudbreak-docs/recipes/">
        <link rel="shortcut icon" href="../img/favicon.ico">

	<title>Recipes - Cloudbreak 1.2.1</title>

        <link href="../css/bootstrap-custom.min.css" rel="stylesheet">
        <link href="../css/font-awesome-4.0.3.css" rel="stylesheet">
        <link href="../css/base.css" rel="stylesheet">
        <link rel="stylesheet" href="../css/highlight.css">

        <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
        <!--[if lt IE 9]>
            <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
            <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
        <![endif]-->

        
    </head>

    <body>

        <div class="navbar navbar-default navbar-fixed-top" role="navigation" background="red">
    <div class="container">

        <!-- Collapsed navigation -->
        <div class="navbar-header">
            
            <!-- Expander button -->
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            

            <!-- Main title -->
            <img class="navbar-logo" src="../img/HWX-RGB-full-no-tagline_500pxh.png" alt="Hortonworks Documentation"
                 width="132" height="52">
            <a class="navbar-brand" href="..">Cloudbreak 1.2.1</a>
        </div>

        <!-- Expanded navigation -->
        <div class="navbar-collapse collapse">
            
                <!-- Main navigation -->
                <ul class="nav navbar-nav">
                
                
                    <li class="dropdown">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown">Home <b class="caret"></b></a>
                        <ul class="dropdown-menu">
                        
                            
<li >
    <a href="..">Introduction</a>
</li>

                        
                            
<li >
    <a href="../architecture/">Architecture</a>
</li>

                        
                            
<li >
    <a href="../onprem/">Installation</a>
</li>

                        
                            
<li >
    <a href="../releasenotes/">Release Notes</a>
</li>

                        
                            
<li >
    <a href="../changelog/">Change Log</a>
</li>

                        
                        </ul>
                    </li>
                
                
                
                    <li >
                        <a href="../aws/">AWS</a>
                    </li>
                
                
                
                    <li >
                        <a href="../azure/">Azure</a>
                    </li>
                
                
                
                    <li >
                        <a href="../gcp/">GCP</a>
                    </li>
                
                
                
                    <li >
                        <a href="../openstack/">OpenStack</a>
                    </li>
                
                
                
                    <li class="dropdown active">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown">Reference <b class="caret"></b></a>
                        <ul class="dropdown-menu">
                        
                            
<li >
    <a href="../api/">API</a>
</li>

                        
                            
<li >
    <a href="../shell/">CLI/Shell</a>
</li>

                        
                            
<li >
    <a href="../ui_account/">Account Management</a>
</li>

                        
                            
<li >
    <a href="../periscope/">Auto-Scaling</a>
</li>

                        
                            
<li >
    <a href="../sssd/">SSSD Configuration</a>
</li>

                        
                            
<li class="active">
    <a href="./">Recipes</a>
</li>

                        
                            
<li >
    <a href="../blueprints/">Blueprints</a>
</li>

                        
                            
<li >
    <a href="../topologies/">Platforms</a>
</li>

                        
                            
<li >
    <a href="../kerberos/">Kerberos</a>
</li>

                        
                            
<li >
    <a href="../mesos/">Mesos</a>
</li>

                        
                            
<li >
    <a href="../spi/">SPI</a>
</li>

                        
                            
<li >
    <a href="../operations/">Operations</a>
</li>

                        
                            
<li >
    <a href="../database/">Migration</a>
</li>

                        
                            
<li >
    <a href="../configuration/">Advanced Configuration</a>
</li>

                        
                            
<li >
    <a href="../development/">Development</a>
</li>

                        
                            
<li >
    <a href="../issues/">Known issues</a>
</li>

                        
                        </ul>
                    </li>
                
                
                </ul>
            

            <ul class="nav navbar-nav navbar-right">
                <li class="dropdown">
                    <a href="#" class="dropdown-toggle" data-toggle="dropdown">Versions <b class="caret"></b></a>
                    <ul class="dropdown-menu" id="versions-dropdown">
                    </ul>
                </li>
                
                <li>
                    <a href="#" data-toggle="modal" data-target="#mkdocs_search_modal">
                        <i class="fa fa-search"></i> Search
                    </a>
                </li>
                
                    <li >
                        <a rel="next" href="../sssd/">
                            <i class="fa fa-arrow-left"></i> Previous
                        </a>
                    </li>
                    <li >
                        <a rel="prev" href="../blueprints/">
                            Next <i class="fa fa-arrow-right"></i>
                        </a>
                    </li>
                
                
                    <li>
                        <a href="https://github.com/sequenceiq/cloudbreak-docs/blob/master/docs/" >
                            
                                <i class="fa fa-github"></i>
                            
                            GitHub
                        </a>
                    </li>
                
            </ul>
        </div>
    </div>
</div>

        <div class="container">
            
                <div class="col-md-3"><div class="bs-sidebar hidden-print affix well" role="complementary">
    <ul class="nav bs-sidenav">
    
        <li class="main active"><a href="#recipes">Recipes</a></li>
        
            <li><a href="#stored-recipes">Stored recipes</a></li>
        
            <li><a href="#downloadable-recipes">Downloadable recipes</a></li>
        
            <li><a href="#sample-recipe-for-ranger">Sample recipe for Ranger</a></li>
        
    
    </ul>
</div></div>
                <div class="col-md-9" role="main">
                    

<h1 id="recipes">Recipes</h1>
<p>With the help of Cloudbreak it is very easy to provision Hadoop clusters in the cloud from an Apache Ambari blueprint. Cloudbreak built in provisioning doesn't contain every use case, so we are introducing the concept of recipes.</p>
<p>Recipes are basically script extensions to a cluster that run on a set of nodes before or after the Ambari cluster installation. With recipes it's quite easy for example to put a JAR file on the Hadoop classpath or run some custom scripts.</p>
<p>In Cloudbreak we supports two ways to configure recipe, we have downloadable and stored recipes.</p>
<h2 id="stored-recipes">Stored recipes</h2>
<p>As the name mentions stored recipes are uploaded and stored in Cloudbreak via web interface or shell.</p>
<p>The easiest way to create a custom recipe:</p>
<ul>
<li>create your own pre and/or post scripts</li>
<li>upload them on shell or web interface</li>
</ul>
<h3 id="add-recipe">Add recipe</h3>
<p>On the web interface under <strong>manage recipes</strong> section you should <strong>create new recipe</strong>. Please choose between SCRIPT, FILE or URL type plugin, and fill required fields.</p>
<p>To add recipe via shell use the following command:</p>
<pre><code>recipe store --name [recipe-name] --executionType [ONE_NODE|ALL_NODES] --preInstallScriptFile /path/of/the/pre-install-script --postInstallScriptFile /path/of/the/post-install-script
</code></pre>

<p>This command has optional parameters:</p>
<p><code>--description</code> "string" description of the recipe</p>
<p><code>--timeout</code> "integer" timeout of the script execution</p>
<p><code>--publicInAccount</code> "flag" flags if the recipe is public in the account</p>
<p>In the background Cloudbreak pushes recipe to Consul key/value store during cluster creation.</p>
<h2 id="downloadable-recipes">Downloadable recipes</h2>
<p>A downloadable recipe should be available on HTTP, HTTPS protocols optionally with basic authentication, or any kind of public Git repository.</p>
<p>This kind of recipe must contain a plugin.toml file, with some basic information about the recipe. Besides this at least a recipe-pre-install or a recipe-post-install script.</p>
<p>Content of plugin.toml:</p>
<pre><code>[plugin]
name = &quot;[recipe-name]&quot;
description = &quot;[description-of-the-recipe]&quot;
version = &quot;1.0&quot;
maintainer_name = &quot;[maintainer-name]&quot;
maintainer_email = &quot;[maintainer-email]&quot;
website_url = &quot;[website-url]&quot;
</code></pre>

<p>Pre- and post scripts are regular shell scripts, and must be executable.</p>
<p>To configure recipe or recipe groups in Cloudbreak you have to create a descriptive JSON file and send it to Cloudbreak via our shell. On web interface you don't need to take care of this file.</p>
<pre><code>{
  &quot;name&quot;: &quot;[recipe-name]&quot;,
  &quot;description&quot;: &quot;[description-of-the-recipe]&quot;,
  &quot;properties&quot;: {
    &quot;[key]&quot;: &quot;[value]&quot;
  },
  &quot;plugins&quot;: {
      &quot;git://github.com/account/recipe.git&quot;: &quot;ONE_NODE&quot;
      &quot;http://user:password@mydomain.com/my-recipe.tar&quot;: &quot;ALL_NODES&quot;
      &quot;https://mydomain.com/my-recipe.zip&quot;: &quot;ALL_NODES&quot;
  }
}
</code></pre>

<p>At this point we need to understand some element of the JSON above.</p>
<p>First of all <code>properties</code>. Properties are saved to Consul key/value store, and they are available from the pre or post script by fetching http://localhost:8500/v1/kv/[key]?raw. This option is a good choice if you want to write reusable recipes.</p>
<p>The next one is <code>plugins</code>. As you read before we support a few kind of protocols, and each of them has their own limitations:</p>
<ul>
<li>
<p>Git</p>
<ul>
<li>git repository must be public (or available from the cluster)</li>
<li>the recipe files must be on the root</li>
<li>only repository default branch supported, there is no opportunity to check out different branch</li>
</ul>
</li>
<li>
<p>HTTP(S)</p>
<ul>
<li>on this kind of protocols you have to bundle your recipe into a tar or zip file</li>
<li>basic authentication is the only way to protect recipe from public</li>
</ul>
</li>
</ul>
<p>Last one is the execution type of the recipe. We supports two options:</p>
<ul>
<li>ONE_NODE means the recipe will execute only one node in the hostgroup</li>
<li>All_NODES runs every single instance in the hostgroup.</li>
</ul>
<h3 id="add-recipe_1">Add recipe</h3>
<p>On the web interface please select URL type plugin, and fill other required fields.</p>
<p>To add recipe via shell use the command(s) below:</p>
<pre><code>recipe add --file /path/of/the/recipe/json
</code></pre>

<p>or</p>
<pre><code>recipe add --url http(s)://mydomain.com/my-recipe.json
</code></pre>

<p>Add command has an optional parameter</p>
<p><code>--publicInAccount</code> is checked all the users belonging to your account will be able to use this recipe for create clusters, but cannot delete it.</p>
<h2 id="sample-recipe-for-ranger">Sample recipe for Ranger</h2>
<p>To be able to install Ranger from a blueprint, a database must be running when Ambari starts to install Ranger Admin. With Cloudbreak a database can be configured and started from a recipe. We've created a sample recipe that can be used to initialize and start a PostgreSQL database that will be able to accept connections from Ranger and store its data. Add the <code>ONE_NODE</code> recipe from <a href="https://github.com/sequenceiq/consul-plugins-ranger-db.git">this URL</a> on the Cloudbreak UI:</p>
<p><img alt="" src="../images/ranger-recipe.png" /></p>
<p>And add this recipe to the same hostgroup where Ranger Admin is installed on the 'Choose Blueprint' when creating a new cluster:</p>
<p><img alt="" src="../images/ranger-hostgroup.png" /></p>
<p>Ranger installation also has some required properties that must be added to the blueprint. We've created a sample one-node blueprint with the necessary configurations to install Ranger Admin and Ranger Usersync. The configuration values in this blueprint match the sample recipe above - they are set to use a PostgreSQL database on the same host where Ranger Admin is installed. Usersync is configured to use UNIX as the authentication method and it should also be installed on the same host where Ranger Admin is installed.</p>
<pre><code>{
  &quot;configurations&quot;: [
    {
      &quot;ranger-site&quot;: {
        &quot;properties_attributes&quot;: {},
        &quot;properties&quot;: {}
      }
    },
    {
      &quot;ranger-hdfs-policymgr-ssl&quot;: {
        &quot;properties_attributes&quot;: {},
        &quot;properties&quot;: {
          &quot;xasecure.policymgr.clientssl.keystore&quot;: &quot;/etc/hadoop/conf/ranger-plugin-keystore.jks&quot;,
          &quot;xasecure.policymgr.clientssl.keystore.credential.file&quot;: &quot;jceks://file{{credential_file}}&quot;,
          &quot;xasecure.policymgr.clientssl.truststore&quot;: &quot;/etc/hadoop/conf/ranger-plugin-truststore.jks&quot;,
          &quot;xasecure.policymgr.clientssl.truststore.credential.file&quot;: &quot;jceks://file{{credential_file}}&quot;
        }
      }
    },
    {
      &quot;ranger-ugsync-site&quot;: {
        &quot;properties_attributes&quot;: {},
        &quot;properties&quot;: {
          &quot;ranger.usersync.enabled&quot;: &quot;true&quot;,
          &quot;ranger.usersync.filesource.file&quot;: &quot;/tmp/usergroup.txt&quot;,
          &quot;ranger.usersync.filesource.text.delimiter&quot;: &quot;,&quot;,
          &quot;ranger.usersync.group.memberattributename&quot;: &quot;member&quot;,
          &quot;ranger.usersync.group.nameattribute&quot;: &quot;cn&quot;,
          &quot;ranger.usersync.group.objectclass&quot;: &quot;groupofnames&quot;,
          &quot;ranger.usersync.group.searchbase&quot;: &quot;ou=groups,dc=hadoop,dc=apache,dc=org&quot;,
          &quot;ranger.usersync.group.searchenabled&quot;: &quot;false&quot;,
          &quot;ranger.usersync.group.searchfilter&quot;: &quot;empty&quot;,
          &quot;ranger.usersync.group.searchscope&quot;: &quot;sub&quot;,
          &quot;ranger.usersync.group.usermapsyncenabled&quot;: &quot;false&quot;,
          &quot;ranger.usersync.ldap.bindalias&quot;: &quot;testldapalias&quot;,
          &quot;ranger.usersync.ldap.binddn&quot;: &quot;cn=admin,dc=xasecure,dc=net&quot;,
          &quot;ranger.usersync.ldap.bindkeystore&quot;: &quot;-&quot;,
          &quot;ranger.usersync.ldap.groupname.caseconversion&quot;: &quot;lower&quot;,
          &quot;ranger.usersync.ldap.searchBase&quot;: &quot;dc=hadoop,dc=apache,dc=org&quot;,
          &quot;ranger.usersync.ldap.url&quot;: &quot;ldap://localhost:389&quot;,
          &quot;ranger.usersync.ldap.user.groupnameattribute&quot;: &quot;memberof, ismemberof&quot;,
          &quot;ranger.usersync.ldap.user.nameattribute&quot;: &quot;cn&quot;,
          &quot;ranger.usersync.ldap.user.objectclass&quot;: &quot;person&quot;,
          &quot;ranger.usersync.ldap.user.searchbase&quot;: &quot;ou=users,dc=xasecure,dc=net&quot;,
          &quot;ranger.usersync.ldap.user.searchfilter&quot;: &quot;empty&quot;,
          &quot;ranger.usersync.ldap.user.searchscope&quot;: &quot;sub&quot;,
          &quot;ranger.usersync.ldap.username.caseconversion&quot;: &quot;lower&quot;,
          &quot;ranger.usersync.logdir&quot;: &quot;/var/log/ranger/usersync&quot;,
          &quot;ranger.usersync.pagedresultsenabled&quot;: &quot;true&quot;,
          &quot;ranger.usersync.pagedresultssize&quot;: &quot;500&quot;,
          &quot;ranger.usersync.policymanager.baseURL&quot;: &quot;{{ranger_external_url}}&quot;,
          &quot;ranger.usersync.policymanager.maxrecordsperapicall&quot;: &quot;1000&quot;,
          &quot;ranger.usersync.policymanager.mockrun&quot;: &quot;false&quot;,
          &quot;ranger.usersync.port&quot;: &quot;5151&quot;,
          &quot;ranger.usersync.sink.impl.class&quot;: &quot;org.apache.ranger.unixusersync.process.PolicyMgrUserGroupBuilder&quot;,
          &quot;ranger.usersync.sleeptimeinmillisbetweensynccycle&quot;: &quot;5&quot;,
          &quot;ranger.usersync.source.impl.class&quot;: &quot;org.apache.ranger.unixusersync.process.UnixUserGroupBuilder&quot;,
          &quot;ranger.usersync.ssl&quot;: &quot;true&quot;,
          &quot;ranger.usersync.unix.minUserId&quot;: &quot;500&quot;
        }
      }
    },
    {
      &quot;admin-properties&quot;: {
        &quot;properties_attributes&quot;: {},
        &quot;properties&quot;: {
          &quot;DB_FLAVOR&quot;: &quot;POSTGRES&quot;,
          &quot;SQL_COMMAND_INVOKER&quot;: &quot;psql&quot;,
          &quot;SQL_CONNECTOR_JAR&quot;: &quot;/var/lib/ambari-agent/tmp/postgres-jdbc-driver.jar&quot;,
          &quot;audit_db_name&quot;: &quot;ranger_audit&quot;,
          &quot;audit_db_user&quot;: &quot;rangerlogger&quot;,
          &quot;db_host&quot;: &quot;localhost:5432&quot;,
          &quot;db_name&quot;: &quot;ranger&quot;,
          &quot;db_root_user&quot;: &quot;postgres&quot;,
          &quot;db_root_password&quot;: &quot;admin&quot;,
          &quot;db_user&quot;: &quot;rangeradmin&quot;,
          &quot;policymgr_external_url&quot;: &quot;http://localhost:6080&quot;,
          &quot;ranger_jdbc_connection_url&quot;: &quot;jdbc:postgresql://{db_host}/ranger&quot;,
          &quot;ranger_jdbc_driver&quot;: &quot;org.postgresql.Driver&quot;
        }
      }
    },
    {
      &quot;ranger-admin-site&quot;: {
        &quot;properties_attributes&quot;: {},
        &quot;properties&quot;: {
          &quot;ranger.audit.source.type&quot;: &quot;db&quot;,
          &quot;ranger.authentication.method&quot;: &quot;UNIX&quot;,
          &quot;ranger.credential.provider.path&quot;: &quot;/etc/ranger/admin/rangeradmin.jceks&quot;,
          &quot;ranger.externalurl&quot;: &quot;{{ranger_external_url}}&quot;,
          &quot;ranger.https.attrib.keystore.file&quot;: &quot;/etc/ranger/admin/keys/server.jks&quot;,
          &quot;ranger.jpa.audit.jdbc.credential.alias&quot;: &quot;rangeraudit&quot;,
          &quot;ranger.jpa.audit.jdbc.dialect&quot;: &quot;{{jdbc_dialect}}&quot;,
          &quot;ranger.jpa.audit.jdbc.driver&quot;: &quot;{{jdbc_driver}}&quot;,
          &quot;ranger.jpa.audit.jdbc.url&quot;: &quot;{{audit_jdbc_url}}&quot;,
          &quot;ranger.jpa.audit.jdbc.user&quot;: &quot;{{ranger_audit_db_user}}&quot;,
          &quot;ranger.jpa.jdbc.credential.alias&quot;: &quot;rangeradmin&quot;,
          &quot;ranger.jpa.jdbc.dialect&quot;: &quot;{{jdbc_dialect}}&quot;,
          &quot;ranger.jpa.jdbc.driver&quot;: &quot;org.postgresql.Driver&quot;,
          &quot;ranger.jpa.jdbc.url&quot;: &quot;jdbc:postgresql://localhost:5432/ranger&quot;,
          &quot;ranger.jpa.jdbc.user&quot;: &quot;{{ranger_db_user}}&quot;,
          &quot;ranger.jpa.jdbc.password&quot;: &quot;{{ranger_db_password}}&quot;,
          &quot;ranger.ldap.ad.domain&quot;: &quot;localhost&quot;,
          &quot;ranger.ldap.ad.url&quot;: &quot;ldap://ad.xasecure.net:389&quot;,
          &quot;ranger.ldap.group.roleattribute&quot;: &quot;cn&quot;,
          &quot;ranger.ldap.group.searchbase&quot;: &quot;ou=groups,dc=xasecure,dc=net&quot;,
          &quot;ranger.ldap.group.searchfilter&quot;: &quot;(member=uid={0},ou=users,dc=xasecure,dc=net)&quot;,
          &quot;ranger.ldap.url&quot;: &quot;ldap://localhost:389&quot;,
          &quot;ranger.ldap.user.dnpattern&quot;: &quot;uid={0},ou=users,dc=xasecure,dc=net&quot;,
          &quot;ranger.service.host&quot;: &quot;{{ranger_host}}&quot;,
          &quot;ranger.service.http.enabled&quot;: &quot;true&quot;,
          &quot;ranger.service.http.port&quot;: &quot;6080&quot;,
          &quot;ranger.service.https.attrib.clientAuth&quot;: &quot;false&quot;,
          &quot;ranger.service.https.attrib.keystore.keyalias&quot;: &quot;mkey&quot;,
          &quot;ranger.service.https.attrib.keystore.pass&quot;: &quot;ranger&quot;,
          &quot;ranger.service.https.attrib.ssl.enabled&quot;: &quot;false&quot;,
          &quot;ranger.service.https.port&quot;: &quot;6182&quot;,
          &quot;ranger.unixauth.remote.login.enabled&quot;: &quot;true&quot;,
          &quot;ranger.unixauth.service.hostname&quot;: &quot;localhost&quot;,
          &quot;ranger.unixauth.service.port&quot;: &quot;5151&quot;
        }
      }
    },
    {
      &quot;ranger-env&quot;: {
        &quot;properties_attributes&quot;: {},
        &quot;properties&quot;: {
          &quot;admin_username&quot;: &quot;admin&quot;,
          &quot;create_db_dbuser&quot;: &quot;true&quot;,
          &quot;ranger_admin_log_dir&quot;: &quot;/var/log/ranger/admin&quot;,
          &quot;ranger_admin_username&quot;: &quot;amb_ranger_admin&quot;,
          &quot;ranger_admin_password&quot;: &quot;amb_ranger_pw&quot;,
          &quot;ranger_group&quot;: &quot;ranger&quot;,
          &quot;ranger_jdbc_connection_url&quot;: &quot;{{ranger_jdbc_connection_url}}&quot;,
          &quot;ranger_jdbc_driver&quot;: &quot;org.postgresql.Driver&quot;,
          &quot;ranger_pid_dir&quot;: &quot;/var/run/ranger&quot;,
          &quot;ranger_user&quot;: &quot;ranger&quot;,
          &quot;ranger_usersync_log_dir&quot;: &quot;/var/log/ranger/usersync&quot;,
          &quot;xml_configurations_supported&quot;: &quot;true&quot;
        }
      }
    },
    {
      &quot;ranger-yarn-security&quot;: {
        &quot;properties_attributes&quot;: {},
        &quot;properties&quot;: {
          &quot;ranger.plugin.yarn.policy.cache.dir&quot;: &quot;/etc/ranger/{{repo_name}}/policycache&quot;,
          &quot;ranger.plugin.yarn.policy.pollIntervalMs&quot;: &quot;30000&quot;,
          &quot;ranger.plugin.yarn.policy.rest.ssl.config.file&quot;: &quot;/etc/yarn/conf/ranger-policymgr-ssl.xml&quot;,
          &quot;ranger.plugin.yarn.policy.rest.url&quot;: &quot;{{policymgr_mgr_url}}&quot;,
          &quot;ranger.plugin.yarn.policy.source.impl&quot;: &quot;org.apache.ranger.admin.client.RangerAdminRESTClient&quot;,
          &quot;ranger.plugin.yarn.service.name&quot;: &quot;{{repo_name}}&quot;
        }
      }
    },
    {
      &quot;ranger-yarn-audit&quot;: {
        &quot;properties_attributes&quot;: {},
        &quot;properties&quot;: {
          &quot;xasecure.audit.credential.provider.file&quot;: &quot;jceks://file{{credential_file}}&quot;,
          &quot;xasecure.audit.db.async.max.flush.interval.ms&quot;: &quot;30000&quot;,
          &quot;xasecure.audit.db.async.max.queue.size&quot;: &quot;10240&quot;,
          &quot;xasecure.audit.db.batch.size&quot;: &quot;100&quot;,
          &quot;xasecure.audit.db.is.async&quot;: &quot;true&quot;,
          &quot;xasecure.audit.destination.db&quot;: &quot;true&quot;,
          &quot;xasecure.audit.hdfs.async.max.flush.interval.ms&quot;: &quot;30000&quot;,
          &quot;xasecure.audit.hdfs.async.max.queue.size&quot;: &quot;1048576&quot;,
          &quot;xasecure.audit.destination.hdfs.dir&quot;: &quot;/ranger/audit/%app-type%/%time:yyyyMMdd%&quot;,
          &quot;xasecure.audit.hdfs.config.destination.file&quot;: &quot;%hostname%-audit.log&quot;,
          &quot;xasecure.audit.hdfs.config.destination.flush.interval.seconds&quot;: &quot;900&quot;,
          &quot;xasecure.audit.hdfs.config.destination.open.retry.interval.seconds&quot;: &quot;60&quot;,
          &quot;xasecure.audit.hdfs.config.destination.rollover.interval.seconds&quot;: &quot;86400&quot;,
          &quot;xasecure.audit.hdfs.config.encoding&quot;: &quot;&quot;,
          &quot;xasecure.audit.hdfs.config.local.archive.directory&quot;: &quot;/var/log/yarn/audit/archive&quot;,
          &quot;xasecure.audit.hdfs.config.local.archive.max.file.count&quot;: &quot;10&quot;,
          &quot;xasecure.audit.hdfs.config.local.buffer.directory&quot;: &quot;/var/log/yarn/audit&quot;,
          &quot;xasecure.audit.hdfs.config.local.buffer.file&quot;: &quot;%time:yyyyMMdd-HHmm.ss%.log&quot;,
          &quot;xasecure.audit.hdfs.config.local.buffer.file.buffer.size.bytes&quot;: &quot;8192&quot;,
          &quot;xasecure.audit.hdfs.config.local.buffer.flush.interval.seconds&quot;: &quot;60&quot;,
          &quot;xasecure.audit.hdfs.config.local.buffer.rollover.interval.seconds&quot;: &quot;600&quot;,
          &quot;xasecure.audit.hdfs.is.async&quot;: &quot;true&quot;,
          &quot;xasecure.audit.is.enabled&quot;: &quot;true&quot;,
          &quot;xasecure.audit.jpa.javax.persistence.jdbc.driver&quot;: &quot;{{jdbc_driver}}&quot;,
          &quot;xasecure.audit.jpa.javax.persistence.jdbc.url&quot;: &quot;{{audit_jdbc_url}}&quot;,
          &quot;xasecure.audit.jpa.javax.persistence.jdbc.user&quot;: &quot;{{xa_audit_db_user}}&quot;,
          &quot;xasecure.audit.kafka.async.max.flush.interval.ms&quot;: &quot;1000&quot;,
          &quot;xasecure.audit.kafka.async.max.queue.size&quot;: &quot;1&quot;,
          &quot;xasecure.audit.kafka.broker_list&quot;: &quot;localhost:9092&quot;,
          &quot;xasecure.audit.kafka.is.enabled&quot;: &quot;false&quot;,
          &quot;xasecure.audit.kafka.topic_name&quot;: &quot;ranger_audits&quot;,
          &quot;xasecure.audit.log4j.async.max.flush.interval.ms&quot;: &quot;30000&quot;,
          &quot;xasecure.audit.log4j.async.max.queue.size&quot;: &quot;10240&quot;,
          &quot;xasecure.audit.log4j.is.async&quot;: &quot;false&quot;,
          &quot;xasecure.audit.log4j.is.enabled&quot;: &quot;false&quot;
        }
      }
    },
    {
      &quot;ranger-hdfs-security&quot;: {
        &quot;properties_attributes&quot;: {},
        &quot;properties&quot;: {
          &quot;ranger.plugin.hdfs.policy.cache.dir&quot;: &quot;/etc/ranger/{{repo_name}}/policycache&quot;,
          &quot;ranger.plugin.hdfs.policy.pollIntervalMs&quot;: &quot;30000&quot;,
          &quot;ranger.plugin.hdfs.policy.rest.ssl.config.file&quot;: &quot;/etc/hadoop/conf/ranger-policymgr-ssl.xml&quot;,
          &quot;ranger.plugin.hdfs.policy.rest.url&quot;: &quot;{{policymgr_mgr_url}}&quot;,
          &quot;ranger.plugin.hdfs.policy.source.impl&quot;: &quot;org.apache.ranger.admin.client.RangerAdminRESTClient&quot;,
          &quot;ranger.plugin.hdfs.service.name&quot;: &quot;{{repo_name}}&quot;,
          &quot;xasecure.add-hadoop-authorization&quot;: &quot;true&quot;
        }
      }
    },
    {
      &quot;ranger-yarn-plugin-properties&quot;: {
        &quot;properties_attributes&quot;: {},
        &quot;properties&quot;: {
          &quot;REPOSITORY_CONFIG_USERNAME&quot;: &quot;yarn&quot;,
          &quot;common.name.for.certificate&quot;: &quot;-&quot;,
          &quot;hadoop.rpc.protection&quot;: &quot;-&quot;,
          &quot;policy_user&quot;: &quot;ambari-qa&quot;,
          &quot;ranger-yarn-plugin-enabled&quot;: &quot;No&quot;
        }
      }
    },
    {
      &quot;ranger-hdfs-audit&quot;: {
        &quot;properties_attributes&quot;: {},
        &quot;properties&quot;: {
          &quot;xasecure.audit.credential.provider.file&quot;: &quot;jceks://file{{credential_file}}&quot;,
          &quot;xasecure.audit.db.async.max.flush.interval.ms&quot;: &quot;30000&quot;,
          &quot;xasecure.audit.db.async.max.queue.size&quot;: &quot;10240&quot;,
          &quot;xasecure.audit.db.batch.size&quot;: &quot;100&quot;,
          &quot;xasecure.audit.db.is.async&quot;: &quot;true&quot;,
          &quot;xasecure.audit.destination.db&quot;: &quot;true&quot;,
          &quot;xasecure.audit.destination.hdfs.dir&quot;: &quot;/ranger/audit/%app-type%/%time:yyyyMMdd%&quot;,
          &quot;xasecure.audit.hdfs.async.max.flush.interval.ms&quot;: &quot;30000&quot;,
          &quot;xasecure.audit.hdfs.async.max.queue.size&quot;: &quot;1048576&quot;,
          &quot;xasecure.audit.hdfs.config.destination.file&quot;: &quot;%hostname%-audit.log&quot;,
          &quot;xasecure.audit.hdfs.config.destination.flush.interval.seconds&quot;: &quot;900&quot;,
          &quot;xasecure.audit.hdfs.config.destination.open.retry.interval.seconds&quot;: &quot;60&quot;,
          &quot;xasecure.audit.hdfs.config.destination.rollover.interval.seconds&quot;: &quot;86400&quot;,
          &quot;xasecure.audit.hdfs.config.encoding&quot;: &quot;&quot;,
          &quot;xasecure.audit.hdfs.config.local.archive.directory&quot;: &quot;/var/log/hadoop/audit/archive/%app-type%&quot;,
          &quot;xasecure.audit.hdfs.config.local.archive.max.file.count&quot;: &quot;10&quot;,
          &quot;xasecure.audit.hdfs.config.local.buffer.directory&quot;: &quot;/var/log/hadoop/audit/%app-type%&quot;,
          &quot;xasecure.audit.hdfs.config.local.buffer.file&quot;: &quot;%time:yyyyMMdd-HHmm.ss%.log&quot;,
          &quot;xasecure.audit.hdfs.config.local.buffer.file.buffer.size.bytes&quot;: &quot;8192&quot;,
          &quot;xasecure.audit.hdfs.config.local.buffer.flush.interval.seconds&quot;: &quot;60&quot;,
          &quot;xasecure.audit.hdfs.config.local.buffer.rollover.interval.seconds&quot;: &quot;600&quot;,
          &quot;xasecure.audit.hdfs.is.async&quot;: &quot;true&quot;,
          &quot;xasecure.audit.is.enabled&quot;: &quot;true&quot;,
          &quot;xasecure.audit.jpa.javax.persistence.jdbc.driver&quot;: &quot;{{jdbc_driver}}&quot;,
          &quot;xasecure.audit.jpa.javax.persistence.jdbc.url&quot;: &quot;{{audit_jdbc_url}}&quot;,
          &quot;xasecure.audit.jpa.javax.persistence.jdbc.user&quot;: &quot;{{xa_audit_db_user}}&quot;,
          &quot;xasecure.audit.kafka.async.max.flush.interval.ms&quot;: &quot;1000&quot;,
          &quot;xasecure.audit.kafka.async.max.queue.size&quot;: &quot;1&quot;,
          &quot;xasecure.audit.kafka.broker_list&quot;: &quot;localhost:9092&quot;,
          &quot;xasecure.audit.kafka.is.enabled&quot;: &quot;false&quot;,
          &quot;xasecure.audit.kafka.topic_name&quot;: &quot;ranger_audits&quot;,
          &quot;xasecure.audit.log4j.async.max.flush.interval.ms&quot;: &quot;30000&quot;,
          &quot;xasecure.audit.log4j.async.max.queue.size&quot;: &quot;10240&quot;,
          &quot;xasecure.audit.log4j.is.async&quot;: &quot;false&quot;,
          &quot;xasecure.audit.log4j.is.enabled&quot;: &quot;false&quot;
        }
      }
    },
    {
      &quot;ranger-hdfs-plugin-properties&quot;: {
        &quot;properties_attributes&quot;: {},
        &quot;properties&quot;: {
          &quot;REPOSITORY_CONFIG_USERNAME&quot;: &quot;hadoop&quot;,
          &quot;common.name.for.certificate&quot;: &quot;-&quot;,
          &quot;hadoop.rpc.protection&quot;: &quot;-&quot;,
          &quot;policy_user&quot;: &quot;ambari-qa&quot;,
          &quot;ranger-hdfs-plugin-enabled&quot;: &quot;No&quot;
        }
      }
    },
    {
      &quot;usersync-properties&quot;: {
        &quot;properties_attributes&quot;: {},
        &quot;properties&quot;: {}
      }
    }
  ],
  &quot;host_groups&quot;: [
    {
      &quot;components&quot;: [
        {
          &quot;name&quot;: &quot;NODEMANAGER&quot;
        },
        {
          &quot;name&quot;: &quot;YARN_CLIENT&quot;
        },
        {
          &quot;name&quot;: &quot;HDFS_CLIENT&quot;
        },
        {
          &quot;name&quot;: &quot;HISTORYSERVER&quot;
        },
        {
          &quot;name&quot;: &quot;METRICS_MONITOR&quot;
        },
        {
          &quot;name&quot;: &quot;NAMENODE&quot;
        },
        {
          &quot;name&quot;: &quot;ZOOKEEPER_CLIENT&quot;
        },
        {
          &quot;name&quot;: &quot;RANGER_ADMIN&quot;
        },
        {
          &quot;name&quot;: &quot;SECONDARY_NAMENODE&quot;
        },
        {
          &quot;name&quot;: &quot;MAPREDUCE2_CLIENT&quot;
        },
        {
          &quot;name&quot;: &quot;ZOOKEEPER_SERVER&quot;
        },
        {
          &quot;name&quot;: &quot;AMBARI_SERVER&quot;
        },
        {
          &quot;name&quot;: &quot;DATANODE&quot;
        },
        {
          &quot;name&quot;: &quot;RANGER_USERSYNC&quot;
        },
        {
          &quot;name&quot;: &quot;APP_TIMELINE_SERVER&quot;
        },
        {
          &quot;name&quot;: &quot;METRICS_COLLECTOR&quot;
        },
        {
          &quot;name&quot;: &quot;RESOURCEMANAGER&quot;
        }
      ],
      &quot;configurations&quot;: [],
      &quot;name&quot;: &quot;host_group_1&quot;,
      &quot;cardinality&quot;: &quot;1&quot;
    }
  ],
  &quot;Blueprints&quot;: {
    &quot;stack_name&quot;: &quot;HDP&quot;,
    &quot;stack_version&quot;: &quot;2.3&quot;,
    &quot;blueprint_name&quot;: &quot;ranger-psql-onenode-sample&quot;
  }
}
</code></pre>

<p><strong>Notes</strong></p>
<ul>
<li>Ranger plugins cannot be enabled by default in a blueprint due to some Ambari restrictions, so properties like <code>ranger-hdfs-plugin-enabled</code> must be set to <em>No</em> and the plugins must be enabled from the Ambari UI with the checkboxes and by restarting the necessary services.</li>
<li>If using the UNIX user sync, it may be necessary in some cases to restart the Ranger Usersync Services after the blueprint installation finished if the UNIX users cannot be seen on the Ranger Admin UI.</li>
</ul>
                    <a href="https://github.com/sequenceiq/cloudbreak-docs/blob/master/docs/recipes.md" ><i class="fa fa-github"></i> Edit on GitHub </a>
                </div>
            
        </div>

        <footer class="col-md-12">
            <hr>
            
            <center>Documentation built with <a href="https://gliderlabs.com/pagebuilder">Pagebuilder</a>.</center>
        </footer>

        <script src="../js/jquery-1.10.2.min.js"></script>
        <script src="../js/bootstrap-3.0.3.min.js"></script>
        <script src="../js/highlight.pack.js"></script>
        <script>var base_url = '..';</script>
        <script data-main="../mkdocs/js/search.js" src="../mkdocs/js/require.js"></script>
        <script src="../js/base.js"></script>

        <div class="modal" id="mkdocs_search_modal" tabindex="-1" role="dialog" aria-labelledby="Search Modal" aria-hidden="true">
            <div class="modal-dialog">
                <div class="modal-content">
                    <div class="modal-header">
                        <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
                        <h4 class="modal-title" id="exampleModalLabel">Search</h4>
                    </div>
                    <div class="modal-body">
                        <p>
                            From here you can search these documents. Enter
                            your search terms below.
                        </p>
                        <form role="form">
                            <div class="form-group">
                                <input type="text" class="form-control" placeholder="Search..." id="mkdocs-search-query">
                            </div>
                        </form>
                        <div id="mkdocs-search-results"></div>
                    </div>
                    <div class="modal-footer">
                    </div>
                </div>
            </div>
        </div>

         <script>
           $( document ).ready(function() {
               $.getJSON("http://sequenceiq.com/cloudbreak-docs/versions.json", function(data) {
               $("#versions-dropdown").append('<li><a href="http://sequenceiq.com/cloudbreak-docs/latest">latest ('+data.latest+')</a></li>');
                $.each(data.versions, function( index, value ) {
                  $("#versions-dropdown").append('<li><a href="http://sequenceiq.com/cloudbreak-docs/'+value+'">'+value+'</a></li>');
                });
               });

               <!--AWS Table-->
               $.getJSON("../providers/aws.json", function(data) {
               $("#cloudbreak-deployer-aws-image-details").append('<br>');
               $("#cloudbreak-deployer-aws-image-details").append('<br>');
               $("#cloudbreak-deployer-aws-image-details").append('<table>');
                 $("#cloudbreak-deployer-aws-image-details").append('<col width="290">');
                 $("#cloudbreak-deployer-aws-image-details").append('<col width="290">');
                 $("#cloudbreak-deployer-aws-image-details").append('<thead>');
                  $("#cloudbreak-deployer-aws-image-details").append('<tr>');
                   $("#cloudbreak-deployer-aws-image-details").append('<th halign="center" style="font-size: 14pt;border:none;border-bottom:solid #DDDDDD 1.5pt;padding:6.0pt 6.0pt 6.0pt 6.0pt">' + "Region" + '</th>');
                   $("#cloudbreak-deployer-aws-image-details").append('<th halign="center" style="font-size: 14pt;border:none;border-bottom:solid #DDDDDD 1.5pt;padding:6.0pt 6.0pt 6.0pt 6.0pt">' + "Image Name" + '</th>');
                  $("#cloudbreak-deployer-aws-image-details").append('</tr>');
                 $("#cloudbreak-deployer-aws-image-details").append('</thead>');
                $("#cloudbreak-deployer-aws-image-details").append('<tbody>');
                 $.each(data.metadata, function( index, value ) {
                 if (index.indexOf("region.") === 0) {
                   shortIndex = index.substring(7)
                  $("#cloudbreak-deployer-aws-image-details").append('<tr>');
                   $("#cloudbreak-deployer-aws-image-details").append('<td halign="center" valign="center" text-align="left" style="font-size: 12pt;border:none;border-bottom:solid #DDDDDD 1.5pt;padding:6.0pt 6.0pt 6.0pt 6.0pt">' + shortIndex + '</td>');
                   $("#cloudbreak-deployer-aws-image-details").append('<td halign="center" valign="center" text-align="right" style="font-size: 12pt;border:none;border-bottom:solid #DDDDDD 1.5pt;padding:6.0pt 6.0pt 6.0pt 6.0pt">' + value + '</td>');
                  $("#cloudbreak-deployer-aws-image-details").append('</tr>');
                  }
                 });
                $("#cloudbreak-deployer-aws-image-details").append('</tbody>');
               $("#cloudbreak-deployer-aws-image-details").append('</table>');
               });

               <!--OpenStack CBD-->
               $.getJSON("../providers/openstack.json", function(data) {
               $("#cloudbreak-deployer-image").append('<br>');
               $("#cloudbreak-deployer-image").append('<br>');
               $("#cloudbreak-deployer-image").append('<p style="font-size: 14px;font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;line-height: 1.428571429;color: #555;">Download the latest Cloudbreak Deployer image to your local machine:</p>');
               $("#cloudbreak-deployer-image").append('<pre><code style="font-size: 12pt;color:#333333">curl -O -k https://public-repo-1.hortonworks.com/HDP/cloudbreak/' + data.id + '</code></pre>');
               $("#cloudbreak-deployer-import").append('<br>');
               $("#cloudbreak-deployer-import").append('<br>');
               $("#cloudbreak-deployer-import").append('<p style="font-size: 14px;font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;line-height: 1.428571429;color: #555;">Set the following environment variables for the OpenStack image import:</p>');
               $("#cloudbreak-deployer-import").append('<pre><code style="font-size: 12px;color:#333333">export CBD_LATEST_IMAGE=</code>' + data.id + '</code></p>');
               });

               <!--OpenStack CB-->
               $.getJSON("../providers/openstack_cloudbreak.json", function(data) {
               $("#cloudbreak-image").append('<br>');
               $("#cloudbreak-image").append('<br>');
               $("#cloudbreak-image").append('<p style="font-size: 14px;font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;line-height: 1.428571429;color: #555;">Download the latest Cloudbreak image to your local machine:</p>');
               $("#cloudbreak-image").append('<pre><code style="font-size: 12pt;color:#333333">curl -O -k https://public-repo-1.hortonworks.com/HDP/cloudbreak/' + data.id + '</code></pre>');
               $("#cloudbreak-import").append('<br>');
               $("#cloudbreak-import").append('<br>');
               $("#cloudbreak-import").append('<p style="font-size: 14px;font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;line-height: 1.428571429;color: #555;">This is very similar to the Cloudbrek Deployer. Set the following environment variables for the OpenStack image import:</p>');
               $("#cloudbreak-import").append('<pre><code style="font-size: 12px;color:#333333">export CB_LATEST_IMAGE=</code>' + data.id + '</code></p>');
               });

               <!--GCP-->
               $.getJSON("../providers/gcp.json", function(data) {
               $("#cloudbreak-deployer-gcp-image-details").append('<br>');
               $("#cloudbreak-deployer-gcp-image-details").append('<br>');
               $("#cloudbreak-deployer-gcp-image-details").append('<pre><code style="font-size: 12pt;color:#333333">' + data.gcp.import_script + '</code></pre>');
               });
           });
         </script>
    </body>
</html>
